{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = require(\"nn\")\n",
    "nninit = require(\"nninit\")\n",
    "require 'optim'\n",
    "csvigo =  require(\"csvigo\")\n",
    "require 'torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: pre-processing/train_data/good_train_matrix_file.txt\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: pre-processing/train_data/good_train_label_file.txt\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "window_size = 11, training_size = 11456\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- load trainning_size\n",
    "matrix_words = csvigo.load{path='pre-processing/train_data/good_train_matrix_file.txt', mode='large', separator=' '}\n",
    "classes = {\"O\", \"B-LOC\", \"B-PER\", \"B-ORG\", \"B-TOUR\", \"I-ORG\", \"I-PER\", \"I-TOUR\", \"I-LOC\", \"B-PRO\", \"I-PRO\"}\n",
    "\n",
    "windowSize = #matrix_words[1]\n",
    "trainingSize = #matrix_words\n",
    "\n",
    "data = torch.Tensor(trainingSize, windowSize)\n",
    "for i=1, trainingSize do\n",
    "    for j=1, windowSize do\n",
    "        data[i][j] = tonumber(matrix_words[i][j]) + 1 -- lua index start from 1, not 0\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "-- read labels\n",
    "labelsRaw = csvigo.load{path='pre-processing/train_data/good_train_label_file.txt', mode='large', separator=' '}\n",
    "labels = torch.DoubleTensor(#labelsRaw)\n",
    "for i=1, #labelsRaw do    \n",
    "    labels[i] = tonumber(labelsRaw[i][1]) + 1\n",
    "end\n",
    "\n",
    "print(string.format(\"window_size = %d, training_size = %d\", windowSize, trainingSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: pre-processing/train_data/good_test_matrix_file.txt\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: pre-processing/train_data/good_test_label_file.txt\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "window_size = 11, testing_size = 333446\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- load test_data -- \n",
    "-- load trainning_size\n",
    "matrix_words_test = csvigo.load{path='pre-processing/train_data/good_test_matrix_file.txt', mode='large', separator=' '}\n",
    "testingSize = #matrix_words_test\n",
    "\n",
    "data_test = torch.Tensor(testingSize, windowSize)\n",
    "for i=1, testingSize do\n",
    "    for j=1, windowSize do        \n",
    "        data_test[i][j] = tonumber(matrix_words_test[i][j]) + 1 -- lua index start from 1, not 0\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "-- read labels -- \n",
    "labelsRawTest = csvigo.load{path='pre-processing/train_data/good_test_label_file.txt', mode='large', separator=' '}\n",
    "labels_test = torch.DoubleTensor(#labelsRawTest)\n",
    "for i=1, #labelsRawTest do    \n",
    "     labels_test[i] = tonumber(labelsRawTest[i][1]) + 1\n",
    "end\n",
    "\n",
    "print(string.format(\"window_size = %d, testing_size = %d\", windowSize, testingSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: pre-processing/train_data/total_matrix_final.txt\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: pre-processing/train_data/total_words_final.txt\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Size {rows=16458, cols=200}\t\n",
       "Number of total words = 16458\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- load data \n",
    "w2v_mat = csvigo.load{path='pre-processing/train_data/total_matrix_final.txt', mode='large', separator=' '}\n",
    "\n",
    "rows = #w2v_mat\n",
    "cols = #w2v_mat[1] - 1 -- the last elem is \\n\n",
    "\n",
    "-- load word\n",
    "words = csvigo.load{path='pre-processing/train_data/total_words_final.txt', mode='large', separator=' '}\n",
    "dictSize = #words\n",
    "embeddedSize = cols\n",
    "\n",
    "print (string.format(\"Size {rows=%d, cols=%d}\", rows, cols))\n",
    "print (string.format(\"Number of total words = %d\", dictSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generate new tensor at size 16458 x 200\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_tensor = torch.Tensor(rows, cols)\n",
    "print(string.format(\"Generate new tensor at size %d x %d\", rows, cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv data to a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1, rows do\n",
    "    for j=1, cols do                 \n",
    "        csv_tensor[i][j] = tonumber(w2v_mat[i][j])\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  11\n",
       " 200\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = nn.LookupTable(dictSize, embeddedSize)\n",
    "lookup.weight = csv_tensor\n",
    "\n",
    "print(#lookup:forward(data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]\n",
       "  (1): nn.LookupTable\n",
       "  (2): nn.Reshape(2200)\n",
       "  (3): nn.Linear(2200 -> 20)\n",
       "  (4): nn.HardTanh\n",
       "  (5): nn.Linear(20 -> 11)\n",
       "  (6): nn.SoftMax\n",
       "}\n",
       "{\n",
       "  gradInput : DoubleTensor - empty\n",
       "  modules : \n",
       "    {\n",
       "      1 : \n",
       "        nn.LookupTable\n",
       "        {\n",
       "          output : DoubleTensor - size: 11x200\n",
       "          gradInput : DoubleTensor - empty\n",
       "          copiedInput : true\n",
       "          weight : DoubleTensor - size: 16458x200\n",
       "          _type : torch.DoubleTensor\n",
       "          _input : LongTensor - size: 11\n",
       "          paddingValue : 0\n",
       "          _count : IntTensor - empty\n",
       "          shouldScaleGradByFreq : false\n",
       "          gradWeight : DoubleTensor - size: 16458x200\n",
       "        }\n",
       "      2 : \n",
       "        nn.Reshape(2200)\n",
       "        {\n",
       "          _type : torch.DoubleTensor\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "          size : LongStorage - size: 1\n",
       "          nelement : 2200\n",
       "          batchsize : LongStorage - size: 2\n",
       "        }\n",
       "      3 : \n",
       "        nn.Linear(2200 -> 20)\n",
       "        {\n",
       "          gradBias : DoubleTensor - size: 20\n",
       "          weight : DoubleTensor - size: 20x2200\n",
       "          _type : torch.DoubleTensor\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "          bias : DoubleTensor - size: 20\n",
       "          gradWeight : DoubleTensor - size: 20x2200\n",
       "        }\n",
       "      4 : \n",
       "        nn.HardTanh\n",
       "        {\n",
       "          inplace : false\n",
       "          min_val : -1\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "          max_val : 1\n",
       "          _type : torch.DoubleTensor\n",
       "        }\n",
       "      5 : \n",
       "        nn.Linear(20 -> 11)\n",
       "        {\n",
       "          gradBias : DoubleTensor - size: 11\n",
       "          weight : DoubleTensor - size: 11x20\n",
       "          _type : torch.DoubleTensor\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "          bias : DoubleTensor - size: 11\n",
       "          gradWeight : DoubleTensor - size: 11x20\n",
       "        }\n",
       "      6 : \n",
       "        nn.SoftMax\n",
       "        {\n",
       "          gradInput : DoubleTensor - empty\n",
       "          _type : torch.DoubleTensor\n",
       "          output : DoubleTensor - empty\n",
       "        }\n",
       "    }\n",
       "  _type : torch.DoubleTensor\n",
       "  output : DoubleTensor - empty\n",
       "}\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- some matrix layer --\n",
    "L = 20\n",
    "K = embeddedSize\n",
    "\n",
    "windowSize = 11\n",
    "model = nn.Sequential()\n",
    "model:add(lookup)\n",
    "model:add(nn.Reshape(K*windowSize))\n",
    "model:add(nn.Linear(K*windowSize, L))\n",
    "model:add(nn.HardTanh())\n",
    "model:add(nn.Linear(L, #classes))\n",
    "model:add(nn.SoftMax())\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()\n",
    "x, dl_dx = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "   learningRate = 1e-2,\n",
    "   learningRateDecay = 1e-4,\n",
    "   weightDecay = 1e-3,\n",
    "   momentum = 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11456\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainingSize)\n",
    "step = function(batch_size)\n",
    "    local current_loss = 0\n",
    "    local count = 0\n",
    "    local shuffle = torch.randperm(trainingSize)    \n",
    "    batch_size = batch_size or 200\n",
    "    \n",
    "    for t = 0, trainingSize, batch_size do\n",
    "        if t==trainingSize then\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        -- setup inputs and targets for this mini-batch\n",
    "        local size = math.min(t + batch_size, trainingSize) - t        \n",
    "        local inputs = torch.Tensor(size, windowSize)\n",
    "        local targets = torch.Tensor(size)\n",
    "        for i = 1, size do            \n",
    "            local input = data[shuffle[i+t]]\n",
    "            local target = labels[shuffle[i+t]]            \n",
    "            -- if target == 0 then target = 10 end\n",
    "            inputs[i] = input\n",
    "            targets[i] = target\n",
    "        end\n",
    "        \n",
    "        local feval = function(x_new)\n",
    "            -- reset data\n",
    "            if x ~= x_new then x:copy(x_new) end\n",
    "            dl_dx:zero()\n",
    "\n",
    "            -- perform mini-batch gradient descent            \n",
    "            outputs = model:forward(inputs);            \n",
    "            local loss = criterion:forward(model:forward(inputs), targets)\n",
    "            model:backward(inputs, criterion:backward(model.output, targets))\n",
    "\n",
    "            return loss, dl_dx\n",
    "        end\n",
    "        \n",
    "        _, fs = optim.sgd(feval, x, sgd_params)\n",
    "        -- fs is a table containing value of the loss function\n",
    "        -- (just 1 value for the SGD optimization)\n",
    "        count = count + 1\n",
    "        current_loss = current_loss + fs[1]        \n",
    "   end\n",
    "\n",
    "    -- normalize loss\n",
    "    return current_loss / count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333446\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- eval --\n",
    "print(testingSize)\n",
    "eval = function(batch_size)\n",
    "    local count = 0\n",
    "    batch_size = batch_size or 200        \n",
    "    \n",
    "    for i = 1, testingSize, batch_size do\n",
    "        local size = math.min(i + batch_size - 1, testingSize) - i\n",
    "        local inputs = data_test[{{i,i+size-1}}]\n",
    "        local targets = labels_test[{{i,i+size-1}}]:long()\n",
    "        local outputs = model:forward(inputs)    \n",
    "        local _, indices = torch.max(outputs, 2)                \n",
    "        local guessed_right = indices:eq(targets):sum()\n",
    "        \n",
    "        count = count + guessed_right\n",
    "    end\n",
    "\n",
    "    return count / testingSize\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch: 1 Current loss: -0.099047\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iters = 30\n",
    "do\n",
    "    local last_accuracy = 0\n",
    "    local decreasing = 0\n",
    "    local threshold = 1 -- how many deacreasing epochs we allow\n",
    "    for i = 1, max_iters do\n",
    "        local loss = step(50)        \n",
    "        print(string.format('Epoch: %d Current loss: %4f', i, loss))\n",
    "        local accuracy = eval(50)\n",
    "        print(string.format('Accuracy on the validation set: %4f', accuracy))\n",
    "        if accuracy < last_accuracy then\n",
    "             if decreasing > threshold then break end\n",
    "             decreasing = decreasing + 1\n",
    "        else\n",
    "             decreasing = 0\n",
    "        end\n",
    "        last_accuracy = accuracy\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
